{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa11837",
   "metadata": {},
   "source": [
    "Task 2: Sentiment and Thematic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecadc7",
   "metadata": {},
   "source": [
    "<li>Analyzes sentiment using DistilBERT\n",
    "<li>Extracts keywords and identifies themes\n",
    "<li>Saves analysis results as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6897ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\compat.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\config.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mregistry\u001b[39;00m(confection\u001b[38;5;241m.\u001b[39mregistry):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     optimizers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\types.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GetCoreSchemaHandler\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_schema\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy, has_cupy\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_cupy:\n\u001b[0;32m     30\u001b[0m     get_array_module \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39mget_array_module\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\compat.py:99\u001b[0m\n\u001b[0;32m     95\u001b[0m has_mxnet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     h5py \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\h5py\\__init__.py:25\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# --- Library setup -----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# When importing from the root of the unpacked tarball or git checkout,\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Python sees the \"h5py\" source directory and tries to load it, which fails.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# We tried working around this by using \"package_dir\" but that breaks Cython.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _errors\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_op\u001b[39;00m\n",
      "File \u001b[1;32mh5py\\_errors.pyx:1\u001b[0m, in \u001b[0;36minit h5py._errors\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3929225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.0.post1)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\python\\wpy64-31241\\python-3.12.4.amd64\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: blis, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.3.0 confection-0.1.5 langcodes-3.5.0 spacy-3.8.7 thinc-8.3.6 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3a3291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\thinc\\compat.py\", line 99, in <module>\n",
      "    import h5py\n",
      "  File \"D:\\python\\WPy64-31241\\python-3.12.4.amd64\\Lib\\site-packages\\h5py\\__init__.py\", line 25, in <module>\n",
      "    from . import _errors\n",
      "  File \"h5py\\_errors.pyx\", line 1, in init h5py._errors\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a581442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='analysis.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path):\n",
    "    \"\"\"Load the cleaned review data\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logging.info(f\"Loaded {len(df)} reviews from {csv_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90728949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text for NLP analysis\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase and remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(df):\n",
    "    \"\"\"Analyze sentiment using DistilBERT\"\"\"\n",
    "    logging.info(\"Starting sentiment analysis...\")\n",
    "    \n",
    "    # Initialize the sentiment analysis pipeline\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    \n",
    "    # Process reviews in batches to avoid memory issues\n",
    "    batch_size = 32\n",
    "    sentiments = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df['review_text'][i:i+batch_size].tolist()\n",
    "        batch = [text if pd.notna(text) else \"\" for text in batch]\n",
    "        \n",
    "        # Skip empty strings\n",
    "        valid_indices = [j for j, text in enumerate(batch) if text.strip()]\n",
    "        valid_texts = [text for text in batch if text.strip()]\n",
    "        \n",
    "        if not valid_texts:\n",
    "            continue\n",
    "        \n",
    "        results = sentiment_analyzer(valid_texts)\n",
    "        \n",
    "        # Map results back to original indices\n",
    "        for idx, result in zip(valid_indices, results):\n",
    "            sentiments.append(result['label'])\n",
    "            scores.append(result['score'])\n",
    "        \n",
    "        # Fill missing values for empty strings\n",
    "        for j in range(len(batch)):\n",
    "            if j not in valid_indices:\n",
    "                sentiments.append('NEUTRAL')\n",
    "                scores.append(0.5)\n",
    "    \n",
    "    df['sentiment_label'] = sentiments\n",
    "    df['sentiment_score'] = scores\n",
    "    \n",
    "    logging.info(f\"Sentiment analysis complete. Found {df['sentiment_label'].value_counts().to_dict()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(df):\n",
    "    \"\"\"Extract keywords using TF-IDF\"\"\"\n",
    "    logging.info(\"Extracting keywords...\")\n",
    "    \n",
    "    # Preprocess text for TF-IDF\n",
    "    df['processed_text'] = df['review_text'].apply(preprocess_text)\n",
    "    \n",
    "    # Group by bank to extract keywords per bank\n",
    "    banks = df['bank_name'].unique()\n",
    "    all_keywords = {}\n",
    "    \n",
    "    for bank in banks:\n",
    "        bank_reviews = df[df['bank_name'] == bank]['processed_text']\n",
    "        \n",
    "        # Skip if no reviews\n",
    "        if len(bank_reviews) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Apply TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=100, min_df=2, max_df=0.7)\n",
    "        tfidf_matrix = vectorizer.fit_transform(bank_reviews)\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get top keywords based on TF-IDF scores\n",
    "        tfidf_scores = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "        top_indices = tfidf_scores.argsort()[-30:][::-1]  # Top 30 keywords\n",
    "        top_keywords = [feature_names[i] for i in top_indices]\n",
    "        \n",
    "        all_keywords[bank] = top_keywords\n",
    "        logging.info(f\"Extracted top keywords for {bank}: {', '.join(top_keywords[:10])}\")\n",
    "    \n",
    "    return all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_themes(df, keywords):\n",
    "    \"\"\"Identify themes based on keywords\"\"\"\n",
    "    logging.info(\"Identifying themes...\")\n",
    "    \n",
    "    # Define theme keywords for each bank\n",
    "    theme_definitions = {\n",
    "        'Dashen Bank': {\n",
    "            'UI/UX': ['interface', 'design', 'ui', 'user', 'friendly', 'navigation', 'screen', 'menu'],\n",
    "            'Performance': ['slow', 'fast', 'speed', 'crash', 'bug', 'loading', 'response', 'time'],\n",
    "            'Features': ['feature', 'transfer', 'payment', 'balance', 'transaction', 'service', 'option'],\n",
    "            'Security': ['security', 'login', 'password', 'fingerprint', 'authentication', 'secure', 'protection'],\n",
    "            'Support': ['support', 'customer', 'service', 'help', 'contact', 'assistance', 'resolve']\n",
    "        },\n",
    "        'Commercial Bank of Ethiopia': {\n",
    "            'UI/UX': ['interface', 'design', 'ui', 'user', 'friendly', 'navigation', 'screen', 'menu'],\n",
    "            'Performance': ['slow', 'fast', 'speed', 'crash', 'bug', 'loading', 'response', 'time'],\n",
    "            'Features': ['feature', 'transfer', 'payment', 'balance', 'transaction', 'service', 'option'],\n",
    "            'Security': ['security', 'login', 'password', 'fingerprint', 'authentication', 'secure', 'protection'],\n",
    "            'Support': ['support', 'customer', 'service', 'help', 'contact', 'assistance', 'resolve']\n",
    "        },\n",
    "        'Bank of Abyssinia': {\n",
    "            'UI/UX': ['interface', 'design', 'ui', 'user', 'friendly', 'navigation', 'screen', 'menu'],\n",
    "            'Performance': ['slow', 'fast', 'speed', 'crash', 'bug', 'loading', 'response', 'time'],\n",
    "            'Features': ['feature', 'transfer', 'payment', 'balance', 'transaction', 'service', 'option'],\n",
    "            'Security': ['security', 'login', 'password', 'fingerprint', 'authentication', 'secure', 'protection'],\n",
    "            'Support': ['support', 'customer', 'service', 'help', 'contact', 'assistance', 'resolve']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Enrich theme definitions with extracted keywords\n",
    "    for bank, bank_keywords in keywords.items():\n",
    "        if bank in theme_definitions:\n",
    "            # Add top keywords to appropriate themes based on similarity\n",
    "            for keyword in bank_keywords:\n",
    "                for theme, theme_keywords in theme_definitions[bank].items():\n",
    "                    if any(keyword in k or k in keyword for k in theme_keywords):\n",
    "                        theme_definitions[bank][theme].append(keyword)\n",
    "    \n",
    "    # Identify themes in each review\n",
    "    df['identified_themes'] = ''\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        bank = row['bank_name']\n",
    "        text = row['review_text'].lower() if pd.notna(row['review_text']) else \"\"\n",
    "        \n",
    "        if bank not in theme_definitions or not text:\n",
    "            continue\n",
    "            \n",
    "        themes = []\n",
    "        for theme, keywords in theme_definitions[bank].items():\n",
    "            if any(keyword in text for keyword in keywords):\n",
    "                themes.append(theme)\n",
    "        \n",
    "        df.at[idx, 'identified_themes'] = ';'.join(themes) if themes else 'Unclassified'\n",
    "    \n",
    "    # Log theme distribution\n",
    "    for bank in theme_definitions:\n",
    "        bank_df = df[df['bank_name'] == bank]\n",
    "        logging.info(f\"Theme distribution for {bank}: {bank_df['identified_themes'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7467f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(df, output_path):\n",
    "    \"\"\"Save analysis results to CSV\"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Analysis results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_analysis(input_csv):\n",
    "    \"\"\"Run the complete sentiment and thematic analysis\"\"\"\n",
    "    logging.info(f\"Starting analysis on {input_csv}\")\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(input_csv)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    df = analyze_sentiment(df)\n",
    "    \n",
    "    # Extract keywords\n",
    "    keywords = extract_keywords(df)\n",
    "    \n",
    "    # Identify themes\n",
    "    df = identify_themes(df, keywords)\n",
    "    \n",
    "    # Save results\n",
    "    output_file = input_csv.replace('.csv', '_analyzed.csv')\n",
    "    save_results(df, output_file)\n",
    "    \n",
    "    logging.info(\"Analysis complete\")\n",
    "    return output_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load the cleaned dataset\n",
    "    input_file = r\"aE://KAIM//phase 2//Week 2//Customer-Experience-Analytics-for-Fintech-Apps//data//all_banks_reviews_clean_20250612_205612.csv\"  # Update with your actual filename\n",
    "    run_analysis(input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
